% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Spectra-functions.R, R/Spectra.R
\name{applyProcessing}
\alias{applyProcessing}
\alias{concatenateSpectra}
\alias{combineSpectra}
\alias{joinSpectraData}
\alias{processingLog}
\alias{estimatePrecursorIntensity}
\alias{deisotopeSpectra}
\alias{reduceSpectra}
\alias{scalePeaks}
\alias{filterPrecursorPeaks}
\alias{Spectra}
\alias{Spectra-class}
\alias{[,Spectra-method}
\alias{uniqueMsLevels}
\alias{uniqueMsLevels,Spectra-method}
\alias{combinePeaks}
\alias{Spectra,missing-method}
\alias{Spectra,MsBackend-method}
\alias{Spectra,character-method}
\alias{Spectra,ANY-method}
\alias{setBackend,Spectra,MsBackend-method}
\alias{c,Spectra-method}
\alias{split,Spectra,ANY-method}
\alias{export,Spectra-method}
\alias{acquisitionNum,Spectra-method}
\alias{peaksData,Spectra-method}
\alias{peaksVariables,Spectra-method}
\alias{centroided,Spectra-method}
\alias{centroided<-,Spectra-method}
\alias{collisionEnergy,Spectra-method}
\alias{collisionEnergy<-,Spectra-method}
\alias{dataOrigin,Spectra-method}
\alias{dataOrigin<-,Spectra-method}
\alias{dataStorage,Spectra-method}
\alias{dropNaSpectraVariables,Spectra-method}
\alias{intensity,Spectra-method}
\alias{ionCount,Spectra-method}
\alias{isCentroided,Spectra-method}
\alias{isEmpty,Spectra-method}
\alias{isolationWindowLowerMz,Spectra-method}
\alias{isolationWindowLowerMz<-,Spectra-method}
\alias{isolationWindowTargetMz,Spectra-method}
\alias{isolationWindowTargetMz<-,Spectra-method}
\alias{isolationWindowUpperMz,Spectra-method}
\alias{isolationWindowUpperMz<-,Spectra-method}
\alias{containsMz,Spectra-method}
\alias{containsNeutralLoss,Spectra-method}
\alias{spectrapply,Spectra-method}
\alias{length,Spectra-method}
\alias{msLevel,Spectra-method}
\alias{mz,Spectra-method}
\alias{lengths,Spectra-method}
\alias{polarity,Spectra-method}
\alias{polarity<-,Spectra-method}
\alias{precScanNum,Spectra-method}
\alias{precursorCharge,Spectra-method}
\alias{precursorIntensity,Spectra-method}
\alias{precursorMz,Spectra-method}
\alias{rtime,Spectra-method}
\alias{rtime<-,Spectra-method}
\alias{scanIndex,Spectra-method}
\alias{selectSpectraVariables,Spectra-method}
\alias{smoothed,Spectra-method}
\alias{smoothed<-,Spectra-method}
\alias{spectraData,Spectra-method}
\alias{spectraData<-,Spectra-method}
\alias{spectraNames,Spectra-method}
\alias{spectraNames<-,Spectra-method}
\alias{spectraVariables,Spectra-method}
\alias{tic,Spectra-method}
\alias{$,Spectra-method}
\alias{$<-,Spectra-method}
\alias{[[,Spectra-method}
\alias{[[<-,Spectra-method}
\alias{filterAcquisitionNum,Spectra-method}
\alias{filterEmptySpectra,Spectra-method}
\alias{filterDataOrigin,Spectra-method}
\alias{filterDataStorage,Spectra-method}
\alias{filterFourierTransformArtefacts,Spectra-method}
\alias{filterIntensity,Spectra-method}
\alias{filterIsolationWindow,Spectra-method}
\alias{filterMsLevel,Spectra-method}
\alias{filterMzRange,Spectra-method}
\alias{filterMzValues,Spectra-method}
\alias{filterPolarity,Spectra-method}
\alias{filterPrecursorMz,Spectra-method}
\alias{filterPrecursorMzRange,Spectra-method}
\alias{filterPrecursorMzValues,Spectra-method}
\alias{filterPrecursorCharge,Spectra-method}
\alias{filterPrecursorScan,Spectra-method}
\alias{filterRt,Spectra-method}
\alias{reset,Spectra-method}
\alias{bin,Spectra-method}
\alias{compareSpectra,Spectra,Spectra-method}
\alias{compareSpectra,Spectra,missing-method}
\alias{pickPeaks,Spectra-method}
\alias{replaceIntensitiesBelow,Spectra-method}
\alias{smooth,Spectra-method}
\alias{addProcessing,Spectra-method}
\alias{coreSpectraVariables}
\alias{backendBpparam,Spectra-method}
\alias{combinePeaks,Spectra-method}
\title{The Spectra class to manage and access MS data}
\usage{
applyProcessing(object, f = dataStorage(object), BPPARAM = bpparam(), ...)

concatenateSpectra(x, ...)

combineSpectra(
  x,
  f = x$dataStorage,
  p = x$dataStorage,
  FUN = combinePeaksData,
  ...,
  BPPARAM = bpparam()
)

joinSpectraData(x, y, by.x = "spectrumId", by.y, suffix.y = ".y")

processingLog(x)

estimatePrecursorIntensity(
  x,
  ppm = 10,
  tolerance = 0,
  method = c("previous", "interpolation"),
  msLevel. = 2L,
  f = dataOrigin(x),
  BPPARAM = bpparam()
)

deisotopeSpectra(
  x,
  substDefinition = isotopicSubstitutionMatrix("HMDB_NEUTRAL"),
  tolerance = 0,
  ppm = 10,
  charge = 1
)

reduceSpectra(x, tolerance = 0, ppm = 10)

scalePeaks(x, by = sum, msLevel. = uniqueMsLevels(x))

filterPrecursorPeaks(
  object,
  tolerance = 0,
  ppm = 20,
  mz = c("==", ">="),
  msLevel. = uniqueMsLevels(object)
)

\S4method{Spectra}{missing}(
  object,
  processingQueue = list(),
  metadata = list(),
  ...,
  backend = MsBackendMemory(),
  BPPARAM = bpparam()
)

\S4method{Spectra}{MsBackend}(
  object,
  processingQueue = list(),
  metadata = list(),
  ...,
  BPPARAM = bpparam()
)

\S4method{Spectra}{character}(
  object,
  processingQueue = list(),
  metadata = list(),
  source = MsBackendMzR(),
  backend = source,
  ...,
  BPPARAM = bpparam()
)

\S4method{Spectra}{ANY}(
  object,
  processingQueue = list(),
  metadata = list(),
  source = MsBackendMemory(),
  backend = source,
  ...,
  BPPARAM = bpparam()
)

\S4method{setBackend}{Spectra,MsBackend}(object, backend, f = dataStorage(object), ..., BPPARAM = bpparam())

\S4method{c}{Spectra}(x, ...)

\S4method{split}{Spectra,ANY}(x, f, drop = FALSE, ...)

\S4method{export}{Spectra}(object, backend, ...)

\S4method{acquisitionNum}{Spectra}(object)

\S4method{peaksData}{Spectra}(object, columns = c("mz", "intensity"), ..., BPPARAM = bpparam())

\S4method{peaksVariables}{Spectra}(object)

\S4method{centroided}{Spectra}(object)

\S4method{centroided}{Spectra}(object) <- value

\S4method{collisionEnergy}{Spectra}(object)

\S4method{collisionEnergy}{Spectra}(object) <- value

\S4method{dataOrigin}{Spectra}(object)

\S4method{dataOrigin}{Spectra}(object) <- value

\S4method{dataStorage}{Spectra}(object)

\S4method{dropNaSpectraVariables}{Spectra}(object)

\S4method{intensity}{Spectra}(object, ...)

\S4method{ionCount}{Spectra}(object)

\S4method{isCentroided}{Spectra}(object, ...)

\S4method{isEmpty}{Spectra}(x)

\S4method{isolationWindowLowerMz}{Spectra}(object)

\S4method{isolationWindowLowerMz}{Spectra}(object) <- value

\S4method{isolationWindowTargetMz}{Spectra}(object)

\S4method{isolationWindowTargetMz}{Spectra}(object) <- value

\S4method{isolationWindowUpperMz}{Spectra}(object)

\S4method{isolationWindowUpperMz}{Spectra}(object) <- value

\S4method{containsMz}{Spectra}(
  object,
  mz = numeric(),
  tolerance = 0,
  ppm = 20,
  which = c("any", "all"),
  BPPARAM = bpparam()
)

\S4method{containsNeutralLoss}{Spectra}(
  object,
  neutralLoss = 0,
  tolerance = 0,
  ppm = 20,
  BPPARAM = bpparam()
)

\S4method{spectrapply}{Spectra}(
  object,
  FUN,
  ...,
  chunkSize = integer(),
  f = factor(),
  BPPARAM = SerialParam()
)

\S4method{length}{Spectra}(x)

\S4method{msLevel}{Spectra}(object)

\S4method{mz}{Spectra}(object, ...)

\S4method{lengths}{Spectra}(x, use.names = FALSE)

\S4method{polarity}{Spectra}(object)

\S4method{polarity}{Spectra}(object) <- value

\S4method{precScanNum}{Spectra}(object)

\S4method{precursorCharge}{Spectra}(object)

\S4method{precursorIntensity}{Spectra}(object)

\S4method{precursorMz}{Spectra}(object)

\S4method{rtime}{Spectra}(object)

\S4method{rtime}{Spectra}(object) <- value

\S4method{scanIndex}{Spectra}(object)

\S4method{selectSpectraVariables}{Spectra}(
  object,
  spectraVariables = union(spectraVariables(object), peaksVariables(object))
)

\S4method{smoothed}{Spectra}(object)

\S4method{smoothed}{Spectra}(object) <- value

\S4method{spectraData}{Spectra}(object, columns = spectraVariables(object))

\S4method{spectraData}{Spectra}(object) <- value

\S4method{spectraNames}{Spectra}(object)

\S4method{spectraNames}{Spectra}(object) <- value

\S4method{spectraVariables}{Spectra}(object)

\S4method{tic}{Spectra}(object, initial = TRUE)

\S4method{$}{Spectra}(x, name)

\S4method{$}{Spectra}(x, name) <- value

\S4method{[[}{Spectra}(x, i, j, ...)

\S4method{[[}{Spectra}(x, i, j, ...) <- value

\S4method{[}{Spectra}(x, i, j, ..., drop = FALSE)

\S4method{filterAcquisitionNum}{Spectra}(
  object,
  n = integer(),
  dataStorage = character(),
  dataOrigin = character()
)

\S4method{filterEmptySpectra}{Spectra}(object)

\S4method{filterDataOrigin}{Spectra}(object, dataOrigin = character())

\S4method{filterDataStorage}{Spectra}(object, dataStorage = character())

\S4method{filterFourierTransformArtefacts}{Spectra}(
  object,
  halfWindowSize = 0.05,
  threshold = 0.2,
  keepIsotopes = TRUE,
  maxCharge = 5,
  isotopeTolerance = 0.005
)

\S4method{filterIntensity}{Spectra}(
  object,
  intensity = c(0, Inf),
  msLevel. = uniqueMsLevels(object),
  ...
)

\S4method{filterIsolationWindow}{Spectra}(object, mz = numeric())

\S4method{filterMsLevel}{Spectra}(object, msLevel. = integer())

\S4method{filterMzRange}{Spectra}(
  object,
  mz = numeric(),
  msLevel. = uniqueMsLevels(object),
  keep = TRUE
)

\S4method{filterMzValues}{Spectra}(
  object,
  mz = numeric(),
  tolerance = 0,
  ppm = 20,
  msLevel. = uniqueMsLevels(object),
  keep = TRUE
)

\S4method{filterPolarity}{Spectra}(object, polarity = integer())

\S4method{filterPrecursorMz}{Spectra}(object, mz = numeric())

\S4method{filterPrecursorMzRange}{Spectra}(object, mz = numeric())

\S4method{filterPrecursorMzValues}{Spectra}(object, mz = numeric(), ppm = 20, tolerance = 0)

\S4method{filterPrecursorCharge}{Spectra}(object, z = integer())

\S4method{filterPrecursorScan}{Spectra}(object, acquisitionNum = integer(), f = dataOrigin(object))

\S4method{filterRt}{Spectra}(object, rt = numeric(), msLevel. = uniqueMsLevels(object))

\S4method{reset}{Spectra}(object, ...)

\S4method{bin}{Spectra}(x, binSize = 1L, breaks = NULL, msLevel. = uniqueMsLevels(x), FUN = sum)

\S4method{compareSpectra}{Spectra,Spectra}(
  x,
  y,
  MAPFUN = joinPeaks,
  tolerance = 0,
  ppm = 20,
  FUN = ndotproduct,
  ...,
  SIMPLIFY = TRUE
)

\S4method{compareSpectra}{Spectra,missing}(
  x,
  y = NULL,
  MAPFUN = joinPeaks,
  tolerance = 0,
  ppm = 20,
  FUN = ndotproduct,
  ...,
  SIMPLIFY = TRUE
)

\S4method{pickPeaks}{Spectra}(
  object,
  halfWindowSize = 2L,
  method = c("MAD", "SuperSmoother"),
  snr = 0,
  k = 0L,
  descending = FALSE,
  threshold = 0,
  msLevel. = uniqueMsLevels(object),
  ...
)

\S4method{replaceIntensitiesBelow}{Spectra}(
  object,
  threshold = min,
  value = 0,
  msLevel. = uniqueMsLevels(object)
)

\S4method{smooth}{Spectra}(
  x,
  halfWindowSize = 2L,
  method = c("MovingAverage", "WeightedMovingAverage", "SavitzkyGolay"),
  msLevel. = uniqueMsLevels(x),
  ...
)

\S4method{addProcessing}{Spectra}(object, FUN, ..., spectraVariables = character())

coreSpectraVariables()

\S4method{uniqueMsLevels}{Spectra}(object, ...)

\S4method{backendBpparam}{Spectra}(object, BPPARAM = bpparam())

\S4method{combinePeaks}{Spectra}(
  object,
  tolerance = 0,
  ppm = 20,
  intensityFun = base::mean,
  mzFun = base::mean,
  weighted = TRUE,
  msLevel. = uniqueMsLevels(object),
  ...
)
}
\arguments{
\item{object}{For \code{Spectra}: either a \code{DataFrame} or \code{missing}. See section
on creation of \code{Spectra} objects for details. For all other methods a
\code{Spectra} object.}

\item{f}{For \code{split}: factor defining how to split \code{x}. See \code{\link[base:split]{base::split()}}
for details. For \code{setBackend}: factor defining how to split the data for
parallelized copying of the spectra data to the new backend. For some
backends changing this parameter can lead to errors.
For \code{combineSpectra}: \code{factor} defining the grouping of the spectra that
should be combined. For \code{spectrapply}: \code{factor} how \code{object} should be
splitted. For \code{estimatePrecursorIntensity} and \code{filterPrecursorScan}:
defining which spectra belong to the same original data file (sample).
Defaults to \code{f = dataOrigin(x)}.}

\item{BPPARAM}{Parallel setup configuration. See \code{\link[=bpparam]{bpparam()}} for more
information. This is passed directly to the \code{\link[=backendInitialize]{backendInitialize()}} method
of the \linkS4class{MsBackend}.}

\item{...}{Additional arguments.}

\item{x}{A \code{Spectra} object.}

\item{p}{For \code{combineSpectra}: \code{factor} defining how to split the input
\code{Spectra} for parallel processing. Defaults to \code{x$dataStorage}, i.e.,
depending on the used backend, per-file parallel processing will be
performed.}

\item{FUN}{For \code{addProcessing}: function to be applied to the peak matrix
of each spectrum in \code{object}. For \code{compareSpectra}: function to compare
intensities of peaks between two spectra with each other.
For \code{combineSpectra}: function to combine the (peak matrices) of the
spectra. See section \emph{Data manipulations} and examples below for more
details.
For \code{bin}: function to aggregate intensity values of peaks falling into
the same bin. Defaults to \code{FUN = sum} thus summing up intensities.
For \code{spectrapply} and \code{chunkapply}: function to be applied to \code{Spectra}.}

\item{y}{A \code{Spectra} object. A \code{DataFrame} for \code{joinSpectraData()}.}

\item{by.x}{A \code{character(1)} specifying the spectra variable used
for merging. Default is \code{"spectrumId"}.}

\item{by.y}{A \code{character(1)} specifying the column used for
merging. Set to \code{by.x} if missing.}

\item{suffix.y}{A \code{character(1)} specifying the suffix to be used
for making the names of columns in the merged spectra variables
unique. This suffix will be used to amend \code{names(y)}, while
\code{spectraVariables(x)} will remain unchanged.}

\item{ppm}{For \code{compareSpectra}, \code{containsMz}, \code{deisotopeSpectra},
\code{filterMzValues} and \code{reduceSpectra}: \code{numeric(1)}
defining a relative, m/z-dependent, maximal accepted difference between
m/z values for peaks to be matched (or grouped).}

\item{tolerance}{For \code{compareSpectra}, \code{containsMz}, \code{deisotopeSpectra},
\code{filterMzValues} and \code{reduceSpectra}: \code{numeric(1)} allowing to define
a constant maximal accepted difference between m/z values for peaks
to be matched (or grouped). For \code{containsMz} it can also be of length
equal \code{mz} to specify a different tolerance for each m/z value.}

\item{method}{\itemize{
\item For \code{pickPeaks}: \code{character(1)}, the noise estimators that
should be used, currently the the \emph{M}edian \emph{A}bsolute \emph{D}eviation
(\code{method = "MAD"}) and Friedman's Super Smoother
(\code{method = "SuperSmoother"}) are supported.
\item For \code{smooth}: \code{character(1)}, the smoothing function that should be used,
currently, the Moving-Average- (\code{method = "MovingAverage"}),
Weighted-Moving-Average- (\verb{method = "WeightedMovingAverage")},
Savitzky-Golay-Smoothing (\code{method = "SavitzkyGolay"}) are supported.
\item For \code{estimatePrecursorIntensity}: \code{character(1)} defining whether the
precursor intensity should be estimated on the previous MS1 spectrum
(\code{method = "previous"}, the default) or based on an interpolation on the
previous and next MS1 spectrum (\code{method = "interpolation"}).
}}

\item{msLevel.}{\code{integer} defining the MS level(s) of the spectra to which
the function should be applied (defaults to all MS levels of \code{object}.
For \code{filterMsLevel}: the MS level to which \code{object} should be subsetted.}

\item{substDefinition}{For \code{deisotopeSpectra}: \code{matrix} or \code{data.frame}
with definitions of isotopic substitutions. Uses by default isotopic
substitutions defined from all compounds in the Human Metabolome
Database (HMDB). See \code{\link[=isotopologues]{isotopologues()}} or \code{\link[=isotopicSubstitutionMatrix]{isotopicSubstitutionMatrix()}}
for details.}

\item{charge}{For \code{deisotopeSpectra}: expected charge of the ionized
compounds. See \code{\link[=isotopologues]{isotopologues()}} for details.}

\item{by}{For \code{scalePeaks}: function to calculate a single \code{numeric} from
intensity values of a spectrum by which all intensities (of
that spectrum) should be divided by. The default \code{by = sum} will
divide intensities of each spectrum by the sum of intensities of that
spectrum.}

\item{mz}{For \code{filterIsolationWindow}: \code{numeric(1)} with the m/z value to
filter the object. For \code{filterPrecursorMz} and \code{filterMzRange}:
\code{numeric(2)} defining the lower and upper m/z boundary.
For \code{filterMzValues} and \code{filterPrecursorMzValues}: \code{numeric} with the
m/z values to match peaks or precursor m/z against.}

\item{processingQueue}{For \code{Spectra}: optional \code{list} of
\linkS4class{ProcessingStep} objects.}

\item{metadata}{For \code{Spectra}: optional \code{list} with metadata information.}

\item{backend}{For \code{Spectra}: \linkS4class{MsBackend} to be used as backend. See
section on creation of \code{Spectra} objects for details. For \code{setBackend}:
instance of \linkS4class{MsBackend} that supports \code{setBackend} (i.e. for
which \code{supportsSetBackend} returns \code{TRUE}). Such backends have a
parameter \code{data} in their \code{backendInitialize} function that support
passing the full spectra data to the initialize method. See section on
creation of \code{Spectra} objects for details.
For \code{export}: \linkS4class{MsBackend} to be used to export the data.}

\item{source}{For \code{Spectra}: instance of \linkS4class{MsBackend} that can be used
to import spectrum data from the provided files. See section \emph{Creation
of objects, conversion and changing the backend} for more details.}

\item{drop}{For \code{[}, \code{split}: not considered.}

\item{columns}{For \code{spectraData} accessor: optional \code{character} with column
names (spectra variables) that should be included in the
returned \code{DataFrame}. By default, all columns are returned.
For \code{peaksData} accessor: optional \code{character} with requested columns in
the individual \code{matrix} of the returned \code{list}. Defaults to
\code{c("mz", "value")} but any values returned by \code{peaksVariables(object)}
with \code{object} being the \code{Spectra} object are supported.}

\item{value}{replacement value for \verb{<-} methods. See individual
method description or expected data type.}

\item{which}{for \code{containsMz}: either \code{"any"} or \code{"all"} defining whether any
(the default) or all provided \code{mz} have to be present in the spectrum.}

\item{neutralLoss}{for \code{containsNeutralLoss}: \code{numeric(1)} defining the value
which should be subtracted from the spectrum's precursor m/z.}

\item{chunkSize}{For \code{spectrapply}: size of the chunks into which \code{Spectra}
should be split. This parameter overrides parameters \code{f} and \code{BPPARAM}.}

\item{use.names}{For \code{lengths}: ignored.}

\item{spectraVariables}{For \code{selectSpectraVariables}: \code{character} with the
names of the spectra variables to which the backend should be subsetted.
For \code{addProcessing}: \code{character} with additional spectra variables that
should be passed along to the function defined with \code{FUN}. See function
description for details.}

\item{initial}{For \code{tic}: \code{logical(1)} whether the initially
reported total ion current should be reported, or whether the
total ion current should be (re)calculated on the actual data
(\code{initial = FALSE}, same as \code{ionCount}).}

\item{name}{For \code{$} and \verb{$<-}: the name of the spectra variable to return
or set.}

\item{i}{For \code{[}: \code{integer}, \code{logical} or \code{character} to subset the object.}

\item{j}{For \code{[}: not supported.}

\item{n}{for \code{filterAcquisitionNum}: \code{integer} with the acquisition numbers
to filter for.}

\item{dataStorage}{For \code{filterDataStorage}: \code{character} to define which
spectra to keep.
For \code{filterAcquisitionNum}: optionally specify if filtering should occur
only for spectra of selected \code{dataStorage}.}

\item{dataOrigin}{For \code{filterDataOrigin}: \code{character} to define which
spectra to keep.
For \code{filterAcquisitionNum}: optionally specify if filtering should occurr
only for spectra of selected \code{dataOrigin}.}

\item{halfWindowSize}{\itemize{
\item For \code{pickPeaks}: \code{integer(1)}, used in the
identification of the mass peaks: a local maximum has to be the maximum
in the window from \code{(i - halfWindowSize):(i + halfWindowSize)}.
\item For \code{smooth}: \code{integer(1)}, used in the smoothing algorithm, the window
reaches from \code{(i - halfWindowSize):(i + halfWindowSize)}.
\item For \code{filterFourierTransformArtefacts}: \code{numeric(1)} defining the m/z window
left and right of a peak where to remove fourier transform artefacts.
}}

\item{threshold}{\itemize{
\item For \code{pickPeaks}: a \code{double(1)} defining the proportion of the maximal peak
intensity. Just values above are used for the weighted mean calculation.
\item For \code{replaceIntensitiesBelow}: a \code{numeric(1)} defining the threshold or
a \code{function} to calculate the threshold for each spectrum on its intensity
values. Defaults to \code{threshold = min}.
\item For \code{filterFourierTransformArtefacts}: the relative intensity (to a peak)
below which peaks are considered fourier artefacts. Defaults to
\code{threshold = 0.2} hence removing peaks that have an intensity below 0.2
times the intensity of the tested peak (within the selected
\code{halfWindowSize}).
}}

\item{keepIsotopes}{For \code{filterFourierTransformArtefacts}: whether isotope
peaks should not be removed as fourier artefacts.}

\item{maxCharge}{For \code{filterFourierTransformArtefacts}: the maximum charge
to be considered for isotopes.}

\item{isotopeTolerance}{For \code{filterFourierTransformArtefacts}: the m/z
\code{tolerance} to be used to define whether peaks might be isotopes of
the current tested peak.}

\item{intensity}{For \code{filterIntensity}: \code{numeric} of length 1 or 2 defining
either the lower or the lower and upper intensity limit for the
filtering, or a \code{function} that takes the intensities as input and
returns a \code{logical} (same length then peaks in the spectrum) whether the
peak should be retained or not. Defaults to \code{intensity = c(0, Inf)} thus
only peaks with \code{NA} intensity are removed.}

\item{keep}{For \code{filterMzValues} and \code{filterMzRange}: \code{logical(1)} whether
the matching peaks should be retained (\code{keep = TRUE}, the default\verb{) or dropped (}keep = FALSE`).}

\item{polarity}{for \code{filterPolarity}: \code{integer} specifying the polarity to
to subset \code{object}.}

\item{z}{For \code{filterPrecursorCharge}: \code{integer()} with the precursor charges
to be used as filter.}

\item{acquisitionNum}{for \code{filterPrecursorScan}: \code{integer} with the
acquisition number of the spectra to which the object should be
subsetted.}

\item{rt}{for \code{filterRt}: \code{numeric(2)} defining the retention time range to
be used to subset/filter \code{object}.}

\item{binSize}{For \code{bin}: \code{numeric(1)} defining the size for the m/z bins.
Defaults to \code{binSize = 1}.}

\item{breaks}{For \code{bin}: \code{numeric} defining the m/z breakpoints between bins.}

\item{MAPFUN}{For \code{compareSpectra}: function to map/match peaks between the
two compared spectra. See \code{\link[=joinPeaks]{joinPeaks()}} for more information and possible
functions.}

\item{SIMPLIFY}{For \code{compareSpectra} whether the result matrix should be
\emph{simplified} to a \code{numeric} if possible (i.e. if either \code{x} or \code{y} is
of length 1).}

\item{snr}{For \code{pickPeaks}: \code{double(1)} defining the
\emph{S}ignal-to-\emph{N}oise-\emph{R}atio. The intensity of a local maximum has to be
higher than \code{snr * noise} to be considered as peak.}

\item{k}{For \code{pickPeaks}: \code{integer(1)}, number of values left and right of
the peak that should be considered in the weighted mean calculation.}

\item{descending}{For \code{pickPeaks}: \code{logical}, if \code{TRUE} just values between
the nearest valleys around the peak centroids are used.}

\item{intensityFun}{For \code{combinePeaks}: function to be used to aggregate
intensities for all peaks in each peak group into a single intensity
value.}

\item{mzFun}{For \code{combinePeaks}: function to aggregate m/z values for all
peaks within each peak group into a single m/z value. This parameter
is ignored if \code{weighted = TRUE} (the default).}

\item{weighted}{For \code{combinePeaks}: \code{logical(1)} whether m/z values of peaks
within each peak group should be aggregated into a single m/z value
using an intensity-weighted mean. Defaults to \code{weighted = TRUE}.}
}
\value{
See individual method description for the return value.
}
\description{
The \code{Spectra} class encapsules spectral mass spectrometry data and
related metadata.

It supports multiple data backends, e.g. in-memory (\link{MsBackendMemory},
\code{\link[=MsBackendDataFrame]{MsBackendDataFrame()}}), on-disk as mzML (\code{\link[=MsBackendMzR]{MsBackendMzR()}}) or HDF5
(\code{\link[=MsBackendHdf5Peaks]{MsBackendHdf5Peaks()}}).
}
\details{
The \code{Spectra} class uses by default a lazy data manipulation strategy,
i.e. data manipulations such as performed with \code{replaceIntensitiesBelow} are
not applied immediately to the data, but applied on-the-fly to the spectrum
data once it is retrieved. For some backends that allow to write data back
to the data storage (such as the \code{\link[=MsBackendMemory]{MsBackendMemory()}}, \code{\link[=MsBackendDataFrame]{MsBackendDataFrame()}}
and \code{\link[=MsBackendHdf5Peaks]{MsBackendHdf5Peaks()}}) it is possible to apply to queue with the
\code{applyProcessing} function. See the \emph{Data manipulation and analysis
methods} section below for more details.

To apply arbitrary functions to a \code{Spectra} use the \code{spectrapply} function
(or directly \code{\link[=chunkapply]{chunkapply()}} for chunk-wise processing). See description of
the \code{spectrapply} function below for details.

For details on plotting spectra, see \code{\link[=plotSpectra]{plotSpectra()}}.

Clarifications regarding scan/acquisition numbers and indices:
\itemize{
\item A \code{spectrumId} (or \code{spectrumID}) is a vendor specific field in
the mzML file that contains some information about the
run/spectrum, e.g.: \verb{controllerType=0 controllerNumber=1 scan=5281 file=2}
\item \code{acquisitionNum} is a more a less sanitize spectrum id generated
from the \code{spectrumId} field by \code{mzR} (see
\href{https://github.com/sneumann/mzR/blob/master/src/pwiz/data/msdata/MSData.cpp#L552-L580}{here}).
\item \code{scanIndex} is the \code{mzR} generated sequence number of the
spectrum in the raw file (which doesn't have to be the same as
the \code{acquisitionNum})
}

See also \href{https://github.com/lgatto/MSnbase/issues/525}{this issue}.
}
\section{Creation of objects, conversion, changing the backend and export}{


\code{Spectra} classes can be created with the \code{Spectra} constructor function
which supports the following formats:
\itemize{
\item parameter \code{object} is a \code{data.frame} or \code{DataFrame} containing the
spectrum data. The provided \code{backend} (by default a
\linkS4class{MsBackendMemory}) will be initialized with that data.
\item parameter \code{object} is a \linkS4class{MsBackend} (assumed to be already
initialized).
\item parameter \code{object} is missing, in which case it is supposed that the data
is provided by the \linkS4class{MsBackend} class passed along with the \code{backend}
argument.
\item parameter \code{object} is of type \code{character} and is expected to be the file
names(s) from which spectra should be imported. Parameter \code{source} allows
to define a \linkS4class{MsBackend} that is able to import the data from the
provided source files. The default value for \code{source} is \code{\link[=MsBackendMzR]{MsBackendMzR()}}
which allows to import spectra data from mzML, mzXML or CDF files.
}

With \code{...} additional arguments can be passed to the backend's
\code{\link[=backendInitialize]{backendInitialize()}} method. Parameter \code{backend} allows to specify which
\linkS4class{MsBackend} should be used for data storage.

The backend of a \code{Spectra} object can be changed with the \code{setBackend}
method that takes an instance of the new backend as second parameter
\code{backend}. A call to \code{setBackend(sps, backend = MsBackendDataFrame())}
would for example change the backend of \code{sps} to the \emph{in-memory}
\code{MsBackendDataFrame}. Changing to a backend is only supported if that
backend has a \code{data} parameter in its \code{backendInitialize} method and if
\code{supportsSetBackend} returns \code{TRUE} for that backend. \code{setBackend} will
transfer the full spectra data from the originating backend as a
\code{DataFrame} to the new backend.
Most \emph{read-only} backends do not support \code{setBackend}. It is for example
not possible to change the backend to a \emph{read-only} backend (such as
the \code{\link[=MsBackendMzR]{MsBackendMzR()}} backend).

The definition of the function is:
\code{setBackend(object, backend, ..., f = dataStorage(object), BPPARAM = bpparam())} and its parameters are:
\itemize{
\item parameter \code{object}: the \code{Spectra} object.
\item parameter \code{backend}: an instance of the new backend, e.g.
\verb{[MsBackendMemory()]}.
\item parameter \code{f}: factor allowing to parallelize the change of the backends.
By default the process of copying the spectra data from the original to the
new backend is performed separately (and in parallel) for each file. Users
are advised to use the default setting.
\item parameter \code{...}: optional additional arguments passed to the
\code{\link[=backendInitialize]{backendInitialize()}} method of the new \code{backend}.
\item parameter \code{BPPARAM}: setup for the parallel processing. See \code{\link[=bpparam]{bpparam()}} for
details.
}

Data from a \code{Spectra} object can be \strong{exported} to a file with the \code{export}
function. The actual export of the data has to be performed by the \code{export}
method of the \link{MsBackend} class defined with the mandatory parameter
\code{backend}. Note however that not all backend classes support export of data.
From the \code{MsBackend} classes in the \code{Spectra} package currently only the
\code{MsBackendMzR} backend supports data export (to mzML/mzXML file(s));
see the help page of the \linkS4class{MsBackend} for information on its arguments
or the examples below or the vignette for examples.

The definition of the function is
\code{export(object, backend,  ...)} and its
parameters are:
\itemize{
\item \code{object}: the \code{Spectra} object to be exported.
\item \code{backend}: instance of a class extending \link{MsBackend} which supports export
of the data (i.e. which has a defined \code{export} method).
\item \code{...}: additional parameters specific for the \code{MsBackend} passed with
parameter \code{backend}.
}
}

\section{Accessing spectra data}{

\itemize{
\item \code{$}, \verb{$<-}: gets (or sets) a spectra variable for all spectra in \code{object}.
See examples for details.
\item \code{[[}, \verb{[[<-}: access or set/add a single spectrum variable (column) in the
backend.
\item \code{acquisitionNum}: returns the acquisition number of each
spectrum. Returns an \code{integer} of length equal to the number of
spectra (with \code{NA_integer_} if not available).
\item \code{centroided}, \verb{centroided<-}: gets or sets the centroiding
information of the spectra. \code{centroided} returns a \code{logical}
vector of length equal to the number of spectra with \code{TRUE} if a
spectrum is centroided, \code{FALSE} if it is in profile mode and \code{NA}
if it is undefined. See also \code{isCentroided} for estimating from
the spectrum data whether the spectrum is centroided. \code{value}
for \verb{centroided<-} is either a single \code{logical} or a \code{logical} of
length equal to the number of spectra in \code{object}.
\item \code{collisionEnergy}, \verb{collisionEnergy<-}: gets or sets the
collision energy for all spectra in \code{object}. \code{collisionEnergy}
returns a \code{numeric} with length equal to the number of spectra
(\code{NA_real_} if not present/defined), \verb{collisionEnergy<-} takes a
\code{numeric} of length equal to the number of spectra in \code{object}.
\item \code{coreSpectraVariables}: returns the \emph{core} spectra variables along with
their expected data type.
\item \code{dataOrigin}, \verb{dataOrigin<-}: gets or sets the \emph{data origin} for each
spectrum. \code{dataOrigin} returns a \code{character} vector (same length than
\code{object}) with the origin of the spectra. \verb{dataOrigin<-} expects a
\code{character} vector (same length than \code{object}) with the replacement
values for the data origin of each spectrum.
\item \code{dataStorage}: returns a \code{character} vector (same length than \code{object})
with the data storage location of each spectrum.
\item \code{intensity}: gets the intensity values from the spectra. Returns
a \code{\link[=NumericList]{NumericList()}} of \code{numeric} vectors (intensity values for each
spectrum). The length of the list is equal to the number of
\code{spectra} in \code{object}.
\item \code{ionCount}: returns a \code{numeric} with the sum of intensities for
each spectrum. If the spectrum is empty (see \code{isEmpty}),
\code{NA_real_} is returned.
\item \code{isCentroided}: a heuristic approach assessing if the spectra in
\code{object} are in profile or centroided mode. The function takes
the \code{qtl}th quantile top peaks, then calculates the difference
between adjacent m/z value and returns \code{TRUE} if the first
quartile is greater than \code{k}. (See \code{Spectra:::.isCentroided} for
the code.)
\item \code{isEmpty}: checks whether a spectrum in \code{object} is empty
(i.e. does not contain any peaks). Returns a \code{logical} vector of
length equal number of spectra.
\item \code{isolationWindowLowerMz}, \verb{isolationWindowLowerMz<-}: gets or sets the
lower m/z boundary of the isolation window.
\item \code{isolationWindowTargetMz}, \verb{isolationWindowTargetMz<-}: gets or sets the
target m/z of the isolation window.
\item \code{isolationWindowUpperMz}, \verb{isolationWindowUpperMz<-}: gets or sets the
upper m/z boundary of the isolation window.
\item \code{containsMz}: checks for each of the spectra whether they contain mass
peaks with an m/z equal to \code{mz} (given acceptable difference as defined by
parameters \code{tolerance} and \code{ppm} - see \code{\link[=common]{common()}} for details). Parameter
\code{which} allows to define whether any (\code{which = "any"}, the default) or
all (\code{which = "all"}) of the \code{mz} have to match. The function returns
\code{NA} if \code{mz} is of length 0 or is \code{NA}.
\item \code{containsNeutralLoss}: checks for each spectrum in \code{object} if it has a
peak with an m/z value equal to its precursor m/z - \code{neutralLoss} (given
acceptable difference as defined by parameters \code{tolerance} and \code{ppm}).
Returns \code{NA} for MS1 spectra (or spectra without a precursor m/z).
\item \code{length}: gets the number of spectra in the object.
\item \code{lengths}: gets the number of peaks (m/z-intensity values) per
spectrum. Returns an \code{integer} vector (length equal to the
number of spectra). For empty spectra, \code{0} is returned.
\item \code{msLevel}: gets the spectra's MS level. Returns an integer vector (names
being spectrum names, length equal to the number of spectra) with the MS
level for each spectrum.
\item \code{mz}: gets the mass-to-charge ratios (m/z) from the
spectra. Returns a \code{\link[=NumericList]{NumericList()}} or length equal to the number of
spectra, each element a \code{numeric} vector with the m/z values of
one spectrum.
\item \code{peaksData}: gets the \emph{peaks} matrices for all spectra in \code{object}. The
function returns a \code{\link[=SimpleList]{SimpleList()}} of matrices, each \code{matrix} with columns
\code{"mz"} and \code{"intensity"} with the m/z and intensity values for all peaks of
a spectrum. Optional parameter \code{columns} is passed to the backend's
\code{peaksData} function to allow selection of specific (or additional) peaks
variables (columns) that should be extracted (if available). Importantly,
it is \strong{not} guaranteed that each backend supports this parameter (while
each backend must support extraction of \code{"mz"} and \code{"intensity"} columns).
Parameter \code{columns} defaults to \code{c("mz", "intensity")} but any value
returned from \code{peaksVariables} is supported.
Note also that it is possible to extract the peaks matrices with
\code{as(x, "list")} and \code{as(x, "SimpleList")} as a \code{list} and \code{SimpleList},
respectively. Note however that, in contrast to \code{peaksData}, \code{as} does not
support the parameter \code{columns}.
\item \code{peaksVariables}: lists the available variables for mass peaks provided by
the backend. Default peak variables are \code{"mz"} and \code{"intensity"} (which
all backends need to support and provide), but some backends might provide
additional variables.
These variables correspond to the column names of the \code{numeric} \code{matrix}
representing the peak data (returned by \code{peaksData}).
\item \code{polarity}, \verb{polarity<-}: gets or sets the polarity for each
spectrum.  \code{polarity} returns an \code{integer} vector (length equal
to the number of spectra), with \code{0} and \code{1} representing negative
and positive polarities, respectively. \verb{polarity<-} expects an
\code{integer} vector of length 1 or equal to the number of spectra.
\item \code{precursorCharge}, \code{precursorIntensity}, \code{precursorMz},
\code{precScanNum}, \code{precAcquisitionNum}: gets the charge (\code{integer}),
intensity (\code{numeric}), m/z (\code{numeric}), scan index (\code{integer})
and acquisition number (\code{interger}) of the precursor for MS level >
2 spectra from the object. Returns a vector of length equal to
the number of spectra in \code{object}. \code{NA} are reported for MS1
spectra of if no precursor information is available.
\item \code{rtime}, \verb{rtime<-}: gets or sets the retention times (in seconds)
for each spectrum.  \code{rtime} returns a \code{numeric} vector (length
equal to the number of spectra) with the retention time for each
spectrum.  \verb{rtime<-} expects a numeric vector with length equal
to the number of spectra.
\item \code{scanIndex}: returns an \code{integer} vector with the \emph{scan index}
for each spectrum. This represents the relative index of the
spectrum within each file. Note that this can be different to the
\code{acquisitionNum} of the spectrum which represents the index of the
spectrum during acquisition/measurement (as reported in the mzML file).
\item \code{smoothed},\verb{smoothed<-}: gets or sets whether a spectrum is
\emph{smoothed}. \code{smoothed} returns a \code{logical} vector of length equal
to the number of spectra. \verb{smoothed<-} takes a \code{logical} vector
of length 1 or equal to the number of spectra in \code{object}.
\item \code{spectraData}: gets general spectrum metadata (annotation, also called
header). \code{spectraData} returns a \code{DataFrame}. Note that this
method does by default \strong{not} return m/z or intensity values.
\item \verb{spectraData<-}: \strong{replaces} the full spectra data of the \code{Spectra}
object with the one provided with \code{value}. The use of this function is
disencouraged, as replacing spectra data with values that are in a
different can break the linkage with the associated m/z and intensity
values. If possible, spectra variables (i.e. \emph{columns} of the \code{Spectra})
should be replaced individually. The \verb{spectraData<-} function expects a
\code{DataFrame} to be passed as value.
\item \code{spectraNames}, \verb{spectraNames<-}: gets or sets the spectra names.
\item \code{spectraVariables}: returns a \code{character} vector with the
available spectra variables (columns, fields or attributes)
available in \code{object}.
\item \code{tic}: gets the total ion current/count (sum of signal of a
spectrum) for all spectra in \code{object}. By default, the value
reported in the original raw data file is returned. For an empty
spectrum, \code{0} is returned.
\item \code{uniqueMsLevels}: get the unique MS levels available in \code{object}. This
function is supposed to be more efficient than \code{unique(msLevel(object))}.
}
}

\section{Data subsetting, filtering and merging}{


Subsetting and filtering of \code{Spectra} objects can be performed with the below
listed methods.
\itemize{
\item \code{[}: subsets the spectra keeping only selected elements (\code{i}). The method
\strong{always} returns a \code{Spectra} object.
\item \code{dropNaSpectraVariables}: removes spectra variables (i.e. columns in the
object's \code{spectraData} that contain only missing values (\code{NA}). Note that
while columns with only \code{NA}s are removed, a \code{spectraData} call after
\code{dropNaSpectraVariables} might still show columns containing \code{NA} values
for \emph{core} spectra variables.
\item \code{filterAcquisitionNum}: filters the object keeping only spectra matching
the provided acquisition numbers (argument \code{n}). If \code{dataOrigin} or
\code{dataStorage} is also provided, \code{object} is subsetted to the spectra with
an acquisition number equal to \code{n} \strong{in spectra with matching dataOrigin
or dataStorage values} retaining all other spectra.
Returns the filtered \code{Spectra}.
\item \code{filterDataOrigin}: filters the object retaining spectra matching the
provided \code{dataOrigin}. Parameter \code{dataOrigin} has to be of type
\code{character} and needs to match exactly the data origin value of the
spectra to subset.
Returns the filtered \code{Spectra} object (with spectra ordered according to
the provided \code{dataOrigin} parameter).
\item \code{filterDataStorage}: filters the object retaining spectra stored in the
specified \code{dataStorage}. Parameter \code{dataStorage} has to be of type
\code{character} and needs to match exactly the data storage value of the
spectra to subset.
Returns the filtered \code{Spectra} object (with spectra ordered according to
the provided \code{dataStorage} parameter).
\item \code{filterEmptySpectra}: removes empty spectra (i.e. spectra without peaks).
Returns the filtered \code{Spectra} object (with spectra in their
original order).
\item \code{filterFourierTransformArtefacts}: remove (Orbitrap) fast fourier
artefact peaks from spectra (see examples below). The function iterates
through all intensity ordered peaks in a spectrum and removes all peaks
with an m/z within +/- \code{halfWindowSize} of the current peak if their
intensity is lower than \code{threshold} times the current peak's intensity.
Additional parameters \code{keepIsotopes}, \code{maxCharge} and \code{isotopeTolerance}
allow to avoid removing of potential \verb{[13]C} isotope peaks (\code{maxCharge}
being the maximum charge that should be considered and \code{isotopeTolerance}
the absolute acceptable tolerance for matching their m/z).
See \code{\link[=filterFourierTransformArtefacts]{filterFourierTransformArtefacts()}} for details and background.
\item \code{filterIsolationWindow}: retains spectra that contain \code{mz} in their
isolation window m/z range (i.e. with an \code{isolationWindowLowerMz} <= \code{mz}
and \code{isolationWindowUpperMz} >= \code{mz}. Returns the filtered \code{Spectra}
object (with spectra in their original order).
\item \code{filterMsLevel}: filters object by MS level keeping only spectra matching
the MS level specified with argument \code{msLevel}. Returns the filtered
\code{Spectra} (with spectra in their original order).
\item \code{filterMzRange}: filters the object keeping or removing peaks in each
spectrum that are within the provided m/z range. Whether peaks are
retained or removed can be configured with parameter \code{keep} (default
\code{keep = TRUE}).
\item \code{filterMzValues}: filters the object keeping \strong{all} peaks in each
spectrum that match the provided m/z value(s) (for \code{keep = TRUE}, the
default) or removing \strong{all} of them (for \code{keep = FALSE}). The m/z
matching considers also the absolute \code{tolerance} and m/z-relative
\code{ppm} values. \code{tolerance} and \code{ppm} have to be of length 1.
\item \code{filterPolarity}: filters the object keeping only spectra matching the
provided polarity. Returns the filtered \code{Spectra} (with spectra in their
original order).
\item \code{filterPrecursorCharge}: retains spectra with the defined precursor
charge(s).
\item \code{filterPrecursorMzRange} (previously \code{filterPrecursorMz} which is now
deprecated): retains spectra with a precursor m/z within the
provided m/z range. See examples for details on selecting spectra with
a precursor m/z for a target m/z accepting a small difference in \emph{ppm}.
\item \code{filterPrecursorMzValues}: retains spectra with precursor m/z matching any
of the provided m/z values (given \code{ppm} and \code{tolerance}). Spectra with
missing precursor m/z value (e.g. MS1 spectra) are dropped.
\item \code{filterPrecursorPeaks}: removes peaks from each spectrum in \code{object} with
an m/z equal or larger than the m/z of the precursor, depending on the
value of parameter \code{mz}: for \verb{mz = ==" (the default) peaks with matching m/z (considering an absolute and relative acceptable difference depending on }tolerance\code{and}ppm\verb{, respectively) are removed. For }mz = ">="\verb{all peaks with an m/z larger or equal to the precursor m/z (minus}tolerance\verb{and the}ppm\verb{of the precursor m/z) are removed. Parameter}msLevel.\verb{allows to restrict the filter to certain MS levels (by default the filter is applied to all MS levels). Note that no peaks are removed if the precursor m/z is}NA` (e.g. typically for MS1 spectra).
\item \code{filterPrecursorScan}: retains parent (e.g. MS1) and children scans (e.g.
MS2) of acquisition number \code{acquisitionNum}. Returns the filtered
\code{Spectra} (with spectra in their original order). Parameter \code{f} allows to
define which spectra belong to the same sample or original data file (
defaults to \code{f = dataOrigin(object)}).
\item \code{filterRt}: retains spectra of MS level \code{msLevel} with retention
times (in seconds) within (\code{>=}) \code{rt[1]} and (\code{<=})
\code{rt[2]}. Returns the filtered \code{Spectra} (with spectra in their
original order).
\item \code{reset}: restores the data to its original state (as much as possible):
removes any processing steps from the lazy processing queue and calls
\code{reset} on the backend which, depending on the backend, can also undo e.g.
data filtering operations. Note that a \code{reset} call after \code{applyProcessing}
will not have any effect. See examples below for more information.
\item \code{selectSpectraVariables}: reduces the information within the object to
the selected spectra variables: all data for variables not specified will
be dropped. For mandatory columns (i.e., those listed by
\code{\link[=coreSpectraVariables]{coreSpectraVariables()}}, such as \emph{msLevel}, \emph{rtime} ...) only
the values will be dropped but not the variable itself. Additional (or
user defined) spectra variables will be completely removed.
Returns the filtered \code{Spectra}.
\item \code{split}: splits the \code{Spectra} object based on parameter \code{f} into a \code{list}
of \code{Spectra} objects.
\item \code{joinSpectraData}: Individual spectra variables can be directly
added with the \verb{$<-} or \verb{[[<-} syntax. The \code{joinSpectraData()}
function allows to merge a \code{DataFrame} to the existing spectra
data. This function diverges from the \code{\link[=merge]{merge()}} method in two
main ways:
\itemize{
\item The \code{by.x} and \code{by.y} column names must be of length 1.
\item If variable names are shared in \code{x} and \code{y}, the spectra
variables of \code{x} are not modified. It's only the \code{y}
variables that are appended the suffix defined in
\code{suffix.y}. This is to avoid modifying any core spectra
variables that would lead to an invalid object.
\item Duplicated Spectra keys (i.e. \code{x[[by.x]]}) are not
allowed. Duplicated keys in the \code{DataFrame} (i.e \code{y[[by.y]]})
throw a warning and only the last occurrence is kept. These
should be explored and ideally be removed using for
\code{QFeatures::reduceDataFrame()}, \code{PMS::reducePSMs()} or similar
functions.
}
}

Several \code{Spectra} objects can be concatenated into a single object with the
\code{c} or the \code{concatenateSpectra} function. Concatenation will fail if the
processing queue of any of the \code{Spectra} objects is not empty or if
different backends are used in the \code{Spectra} objects. The spectra variables
of the resulting \code{Spectra} object is the union of the spectra variables of
the individual \code{Spectra} objects.
}

\section{Data manipulation and analysis methods}{


Many data manipulation operations, such as those listed in this section, are
not applied immediately to the spectra, but added to a
\emph{lazy processing/manipulation queue}. Operations stored in this queue are
applied on-the-fly to spectra data each time it is accessed. This lazy
execution guarantees the same functionality for \code{Spectra} objects with
any backend, i.e. backends supporting to save changes to spectrum data
(\link{MsBackendMemory}, \code{\link[=MsBackendDataFrame]{MsBackendDataFrame()}} or \code{\link[=MsBackendHdf5Peaks]{MsBackendHdf5Peaks()}}) as
well as read-only backends (such as the \code{\link[=MsBackendMzR]{MsBackendMzR()}}).
Note that for the former it is possible to apply the processing queue and
write the modified peak data back to the data storage with the
\code{applyProcessing} function.
\itemize{
\item \code{addProcessing}: adds an arbitrary function that should be applied to the
peaks matrix of every spectrum in \code{object}. The function (can be passed
with parameter \code{FUN}) is expected to take a peaks matrix as input and to
return a peaks matrix. A peaks matrix is a numeric matrix with two columns,
the first containing the m/z values of the peaks and the second the
corresponding intensities. The function has to have \code{...} in its
definition. Additional arguments can be passed with \code{...}. With parameter
\code{spectraVariables} it is possible to define additional spectra variables
from \code{object} that should be passed to the function \code{FUN}. These will be
passed by their name (e.g. specifying \code{spectraVariables = "precursorMz"}
will pass the spectra's precursor m/z as a parameter named \code{precursorMz}
to the function. The only exception is the spectra's MS level, these will
be passed to the function as a parameter called \code{spectrumMsLevel} (i.e.
with \code{spectraVariables = "msLevel"} the MS levels of each spectrum will be
submitted to the function as a parameter called \code{spectrumMsLevel}).
Examples are provided in the package vignette.
\item \code{applyProcessing}: for \code{Spectra} objects that use a \strong{writeable} backend
only: apply all steps from the lazy processing queue to the peak data and
write it back to the data storage. Parameter \code{f} allows to specify how
\code{object} should be split for parallel processing. This should either be
equal to the \code{dataStorage}, or \code{f = rep(1, length(object))} to disable
parallel processing alltogether. Other partitionings might result in
errors (especially if a \code{MsBackendHdf5Peaks} backend is used).
\item \code{bin}: aggregates individual spectra into discrete (m/z) bins. Binning is
performed only on spectra of the specified MS level(s) (parameter
\code{msLevel}, by default all MS levels of \code{x}). The bins can be defined with
parameter \code{breaks} which by default are equally sized bins, with size
being defined by parameter \code{binSize}, from the minimal to the maximal m/z
of all spectra (of MS level \code{msLevel}) within \code{x}. The same bins are used
for all spectra in \code{x}. All intensity values for peaks falling into the
same bin are aggregated using the function provided with parameter \code{FUN}
(defaults to \code{FUN = sum}, i.e. all intensities are summed up). Note that
the binning operation is applied to the peak data on-the-fly upon data
access and it is possible to \emph{revert} the operation with the \code{reset}
function (see description of \code{reset} above).
\item \code{combinePeaks}: combines mass peaks within each spectrum with a difference
in their m/z values that is smaller than the maximal acceptable difference
defined by \code{ppm} and \code{tolerance}. Parameters \code{intensityFun} and \code{mzFun}
allow to define functions to aggregate the intensity and m/z values for
each such group of peaks. With \code{weighted = TRUE} (the default), the m/z
value of the combined peak is calculated using an intensity-weighted mean
and parameter \code{mzFun} is ignored. The \code{\link[MsCoreUtils:group]{MsCoreUtils::group()}} function is
used for the grouping of mass peaks. Parameter \code{msLevel.} allows to
define selected MS levels for which peaks should be combined. This
function returns a \code{Spectra} with the same number of spectra than the
input object, but with possibly combined peaks within each spectrum.
Additional peak variables (other than \code{"mz"} and \code{"intensity"}) are
dropped (i.e. their values are replaced with \code{NA}) for combined peaks
unless they are constant across the combined peaks. See also
\code{reduceSpectra} for a function to select a single \emph{representative}
mass peak for each peak group.
\item \code{combineSpectra}: combine sets of spectra into a single spectrum per set.
For each spectrum group (set), spectra variables from the first spectrum
are used and the peak matrices are combined using the function specified
with \code{FUN}, which defaults to \code{\link[=combinePeaksData]{combinePeaksData()}}. Please refer to the
\code{\link[=combinePeaksData]{combinePeaksData()}} help page for details and options of the actual
combination of peaks across the sets of spectra and to the package vignette
for examples and alternative ways to aggregate spectra.
The sets of spectra can be specified with parameter \code{f}.
In addition it is possible to define, with parameter \code{p} if and how to
split the input data for parallel processing.
This defaults to \code{p = x$dataStorage} and hence a per-file parallel
processing is applied for \code{Spectra} with file-based backends (such as the
\code{\link[=MsBackendMzR]{MsBackendMzR()}}).
Prior combination of the spectra all processings queued in the lazy
evaluation queue are applied. Be aware that calling \code{combineSpectra} on a
\code{Spectra} object with certain backends that allow modifications might
\strong{overwrite} the original data. This does not happen with a
\code{MsBackendMemory} or \code{MsBackendDataFrame} backend, but with a
\code{MsBackendHdf5Peaks} backend the m/z and intensity values in the original
hdf5 file(s) will be overwritten.
The function returns a \code{Spectra} of length equal to the unique levels
of \code{f}.
\item \code{compareSpectra}: compares each spectrum in \code{x} with each spectrum in \code{y}
using the function provided with \code{FUN} (defaults to \code{\link[=ndotproduct]{ndotproduct()}}). If
\code{y} is missing, each spectrum in \code{x} is compared with each other spectrum
in \code{x}.
The matching/mapping of peaks between the compared spectra is done with the
\code{MAPFUN} function. The default \code{\link[=joinPeaks]{joinPeaks()}} matches peaks of both spectra
and allows to keep all peaks from the first spectrum (\code{type = "left"}),
from the second (\code{type = "right"}), from both (\code{type = "outer"}) and to
keep only matching peaks (\code{type = "inner"}); see \code{\link[=joinPeaks]{joinPeaks()}} for more
information and examples). The \code{MAPFUN} function should have parameters
\code{x}, \code{y}, \code{xPrecursorMz} and \code{yPrecursorMz} as these values are passed to
the function. In addition to \code{joinPeaks()} also \code{\link[=joinPeaksGnps]{joinPeaksGnps()}} is
supported for GNPS-like similarity score calculations. Note that
\code{joinPeaksGnps} should only be used in combination with
\code{FUN = MsCoreUtils::gnps} (see \code{\link[=joinPeaksGnps]{joinPeaksGnps()}} for more information and
details).
\code{FUN} is supposed to be a function to compare intensities of (matched)
peaks of the two spectra that are compared. The function needs to take two
matrices with columns \code{"mz"} and \code{"intensity"} as input and is supposed
to return a single numeric as result. In addition to the two peak matrices
the spectra's precursor m/z values are passed to the function as parameters
\code{xPrecursorMz} (precursor m/z of the \code{x} peak matrix) and \code{yPrecursorMz}
(precursor m/z of the \code{y} peak matrix). Additional parameters to functions
\code{FUN} and \code{MAPFUN} can be passed with \code{...}.
The function returns a \code{matrix} with the results of \code{FUN} for each
comparison, number of rows equal to \code{length(x)} and number of columns
equal \code{length(y)} (i.e. element in row 2 and column 3 is the result from
the comparison of \code{x[2]} with \code{y[3]}). If \code{SIMPLIFY = TRUE} the \code{matrix}
is \emph{simplified} to a \code{numeric} if length of \code{x} or \code{y} is one.
\item \code{deisotopeSpectra}: \emph{deisotopes} each spectrum keeping only the
monoisotopic peak for groups of isotopologues. Isotopologues are
estimated using the \code{\link[=isotopologues]{isotopologues()}} function from the \emph{MetaboCoreUtils}
package. Note that the default parameters for isotope
prediction/detection have been determined using data from the Human
Metabolome Database (HMDB) and isotopes for elements other than CHNOPS
might not be detected. See parameter \code{substDefinition} in the
documentation of \code{\link[=isotopologues]{isotopologues()}} for more information. The approach
and code to define the parameters for isotope prediction is described
\href{https://github.com/EuracBiomedicalResearch/isotopologues}{here}.
\item \code{estimatePrecursorIntensity}: defines the precursor intensities for MS2
spectra using the intensity of the matching MS1 peak from the
closest MS1 spectrum (i.e. the last MS1 spectrum measured before the
respective MS2 spectrum). With \code{method = "interpolation"} it is also
possible to calculate the precursor intensity based on an interpolation of
intensity values (and retention times) of the matching MS1 peaks from the
previous and next MS1 spectrum. See below for an example.
\item \code{filterIntensity}: filters each spectrum keeping only peaks with
intensities that are within the provided range or match the criteria of
the provided function. For the former, parameter \code{intensity} has to be a
\code{numeric} defining the intensity range, for the latter a \code{function} that
takes the intensity values of the spectrum and returns a \code{logical} whether
the peak should be retained or not (see examples below for details) -
additional parameters to the function can be passed with \code{...}. To
remove only peaks with intensities below a certain threshold, say 100, use
\code{intensity = c(100, Inf)}. Note: also a single value can be passed with
the \code{intensity} parameter in which case an upper limit of \code{Inf} is used.
Note that this function removes also peaks with missing intensities
(i.e. an intensity of \code{NA}). Parameter \code{msLevel.} allows to restrict the
filtering to spectra of the specified MS level(s).
\item \code{neutralLoss}: calculates neutral loss spectra for fragment spectra. See
\code{\link[=neutralLoss]{neutralLoss()}} for detailed documentation.
\item \code{processingLog}: returns a \code{character} vector with the processing log
messages.
\item \code{reduceSpectra}: keeps for groups of peaks with similar m/z values in
(given \code{ppm} and \code{tolerance}) in each spectrum only the peak with the
highest intensity removing all other peaks hence \emph{reducing} each
spectrum to the highest intensity peaks per \emph{peak group}.
Peak groups are defined using the \code{\link[=group]{group()}} function from the
\emph{MsCoreUtils} package. See also the \code{combinePeaks} function for an
alternative function to combine peaks within each spectrum.
\item \code{scalePeaks}: scales intensities of peaks within each spectrum depending on
parameter \code{by}. With \code{by = sum} (the default) peak intensities are divided
by the sum of peak intensities within each spectrum. The sum of
intensities is thus 1 for each spectrum after scaling. Parameter
\code{msLevel.} allows to apply the scaling of spectra of a certain MS level.
By default (\code{msLevel. = uniqueMsLevels(x)}) intensities for all
spectra will be scaled.
\item \code{spectrapply}: applies a given function to each individual spectrum or sets
of a \code{Spectra} object. By default, the \code{Spectra} is split into individual
spectra (i.e. \code{Spectra} of length 1) and the function \code{FUN} is applied to
each of them. An alternative splitting can be defined with parameter \code{f}.
Parameters for \code{FUN} can be passed using \code{...}.
The returned result and its order depend on the function \code{FUN} and how
\code{object} is split (hence on \code{f}, if provided). Parallel processing is
supported and can be configured with parameter \code{BPPARAM}, is however only
suggested for computational intense \code{FUN}.
As an alternative to the (eventual parallel) processing of the full
\code{Spectra}, \code{spectrapply} supports also a chunk-wise processing. For this,
parameter \code{chunkSize} needs to be specified. \code{object} is then split into
chunks of size \code{chunkSize} which are then (stepwise) processed by \code{FUN}.
This guarantees a lower memory demand (especially for on-disk backends)
since only the data for one chunk needs to be loaded into memory in each
iteration. Note that by specifying \code{chunkSize}, parameters \code{f} and
\code{BPPARAM} will be ignored.
See also \code{\link[=chunkapply]{chunkapply()}} or examples below for details on chunk-wise
processing.
\item \code{smooth}: smooth individual spectra using a moving window-based approach
(window size = \code{2 * halfWindowSize}). Currently, the
Moving-Average- (\code{method = "MovingAverage"}),
Weighted-Moving-Average- (\verb{method = "WeightedMovingAverage")},
weights depending on the distance of the center and calculated
\code{1/2^(-halfWindowSize:halfWindowSize)}) and
Savitzky-Golay-Smoothing (\code{method = "SavitzkyGolay"}) are supported.
For details how to choose the correct \code{halfWindowSize} please see
\code{\link[MsCoreUtils:smooth]{MsCoreUtils::smooth()}}.
\item \code{pickPeaks}: picks peaks on individual spectra using a moving window-based
approach (window size = \code{2 * halfWindowSize}). For noisy spectra there
are currently two different noise estimators available,
the \emph{M}edian \emph{A}bsolute \emph{D}eviation (\code{method = "MAD"}) and
Friedman's Super Smoother (\code{method = "SuperSmoother"}),
as implemented in the \code{\link[MsCoreUtils:noise]{MsCoreUtils::noise()}}.
The method supports also to optionally \emph{refine} the m/z value of
the identified centroids by considering data points that belong (most
likely) to the same mass peak. Therefore the m/z value is calculated as an
intensity weighted average of the m/z values within the peak region.
The peak region is defined as the m/z values (and their respective
intensities) of the \code{2 * k} closest signals to the centroid or the closest
valleys (\code{descending = TRUE}) in the \code{2 * k} region. For the latter the \code{k}
has to be chosen general larger. See \code{\link[MsCoreUtils:refineCentroids]{MsCoreUtils::refineCentroids()}} for
details.
If the ratio of the signal to the highest intensity of the peak is below
\code{threshold} it will be ignored for the weighted average.
\item \code{replaceIntensitiesBelow}: replaces intensities below a specified
threshold with the provided \code{value}. Parameter \code{threshold} can be either
a single numeric value or a function which is applied to all non-\code{NA}
intensities of each spectrum to determine a threshold value for each
spectrum. The default is \code{threshold = min} which replaces all values
which are <= the minimum intensity in a spectrum with \code{value} (the
default for \code{value} is \code{0}). Note that the function specified with
\code{threshold} is expected to have a parameter \code{na.rm} since \code{na.rm = TRUE}
will be passed to the function. If the spectrum is in profile mode,
ranges of successive non-0 peaks <= \code{threshold} are set to 0.
Parameter \code{msLevel.} allows to apply this to only spectra of certain MS
level(s).
}
}

\section{Parallel processing}{


Some \code{Spectra} functions have build-in parallel processing that can be
configured by passing the parallel processing setup with the \code{BPPARAM}
function argument (which defaults to \code{BPPARAM = bpparam()}, thus uses
the default set up). Most functions have an additional parameter \code{f} that
allows to define how \code{Spectra} will be split to perform parallel processing.
This parameter \code{f} defaults to \code{f = dataStorage(object)} and hence
parallel processing is performed \emph{by file} (if a file-based, on-disk
backend such as \code{MsBackendMzR} is used). Some \code{MsBackend} classes might
however not support parallel processing. The \code{backendBpparam} function
allows to evaluate wheter a \code{Spectra} (respectively its \code{MsBackend})
supports a certain parallel processing setup. Calling
\code{backendBpparam(sps, BPPARAM = MulticoreParam(3))} on a \code{Spectra} object
\code{sps} would return \code{SerialParam()} in case the backend of the \code{Spectra}
object does not support parallel processing. All functions listed below
use this same function to eventually disable parallel processing to
avoid failure of a function call.

The functions with build-in parallel processing capabilities are:
\itemize{
\item \code{applyProcessing}.
\item \code{combineSpectra}.
\item \code{containsMz} (does not provide a parameter \code{f}, but performs parallel
processing separate for \code{dataStorage}).
\item \code{containsNeutralLoss} (same as \code{containsMz}).
\item \code{estimatePrecursorIntensity}.
\item \code{setBackend}.
\item \code{Spectra} (that passes the \code{BPPARAM} to the \code{backendInitialize} of the
used \code{MsBackend}).
\item \code{spectrapply}.
}
}

\examples{

## Create a Spectra providing a `DataFrame` containing the spectrum data.

spd <- DataFrame(msLevel = c(1L, 2L), rtime = c(1.1, 1.2))
spd$mz <- list(c(100, 103.2, 104.3, 106.5), c(45.6, 120.4, 190.2))
spd$intensity <- list(c(200, 400, 34.2, 17), c(12.3, 15.2, 6.8))

data <- Spectra(spd)
data

## Get the number of spectra
length(data)

## Get the number of peaks per spectrum
lengths(data)

## Create a Spectra from mzML files and use the `MsBackendMzR` on-disk
## backend.
sciex_file <- dir(system.file("sciex", package = "msdata"),
    full.names = TRUE)
sciex <- Spectra(sciex_file, backend = MsBackendMzR())
sciex

## The MS data is on disk and will be read into memory on-demand. We can
## however change the backend to a MsBackendMemory backend which will
## keep all of the data in memory.
sciex_im <- setBackend(sciex, MsBackendMemory())
sciex_im

## The `MsBackendMemory()` supports the `setBackend` method:
supportsSetBackend(MsBackendMemory())

## Thus, it is possible to change to that backend with `setBackend`. Most
## read-only backends however don't support that, such as the
## `MsBackendMzR` and `setBackend` would fail to change to that backend.
supportsSetBackend(MsBackendMzR())

## The on-disk object `sciex` is light-weight, because it does not keep the
## MS peak data in memory. The `sciex_im` object in contrast keeps all the
## data in memory and its size is thus much larger.
object.size(sciex)
object.size(sciex_im)

## The spectra variable `dataStorage` returns for each spectrum the location
## where the data is stored. For in-memory objects:
head(dataStorage(sciex_im))

## While objects that use an on-disk backend will list the files where the
## data is stored.
head(dataStorage(sciex))

## The spectra variable `dataOrigin` returns for each spectrum the *origin*
## of the data. If the data is read from e.g. mzML files, this will be the
## original mzML file name:
head(dataOrigin(sciex))
head(dataOrigin(sciex_im))


## ---- ACCESSING AND ADDING DATA ----

## Get the MS level for each spectrum.
msLevel(data)

## Alternatively, we could also use $ to access a specific spectra variable.
## This could also be used to add additional spectra variables to the
## object (see further below).
data$msLevel

## Get the intensity and m/z values.
intensity(data)
mz(data)

## Determine whether one of the spectra has a specific m/z value
containsMz(data, mz = 120.4)

## Accessing spectra variables works for all backends:
intensity(sciex)
intensity(sciex_im)

## Get the m/z for the first spectrum.
mz(data)[[1]]

## Get the peak data (m/z and intensity values).
pks <- peaksData(data)
pks
pks[[1]]
pks[[2]]

## Note that we could get the same resulb by coercing the `Spectra` to
## a `list` or `SimpleList`:
as(data, "list")
as(data, "SimpleList")

## List all available spectra variables (i.e. spectrum data and metadata).
spectraVariables(data)

## For all *core* spectrum variables accessor functions are available. These
## return NA if the variable was not set.
centroided(data)
dataStorage(data)
rtime(data)
precursorMz(data)

## The core spectra variables are:
coreSpectraVariables()

## Add an additional metadata column.
data$spectrum_id <- c("sp_1", "sp_2")

## List spectra variables, "spectrum_id" is now also listed
spectraVariables(data)

## Get the values for the new spectra variable
data$spectrum_id

## Extract specific spectra variables.
spectraData(data, columns = c("spectrum_id", "msLevel"))

## Drop spectra variable data and/or columns.
res <- selectSpectraVariables(data, c("mz", "intensity"))

## This removed the additional columns "spectrum_id" and deleted all values
## for all spectra variables, except "mz" and "intensity".
spectraData(res)

## Compared to the data before selectSpectraVariables.
spectraData(data)


## ---- SUBSETTING, FILTERING AND COMBINING

## Subset to all MS2 spectra.
data[msLevel(data) == 2]

## Same with the filterMsLevel function
filterMsLevel(data, 2)

## Below we combine the `data` and `sciex_im` objects into a single one.
data_comb <- c(data, sciex_im)

## The combined Spectra contains a union of all spectra variables:
head(data_comb$spectrum_id)
head(data_comb$rtime)
head(data_comb$dataStorage)
head(data_comb$dataOrigin)

## Filter a Spectra for a target precursor m/z with a tolerance of 10ppm
spd$precursorMz <- c(323.4, 543.2302)
data_filt <- Spectra(spd)
filterPrecursorMzRange(data_filt, mz = 543.23 + ppm(c(-543.23, 543.23), 10))

## Filter a Spectra keeping only peaks matching certain m/z values
sps_sub <- filterMzValues(data, mz = c(103, 104), tolerance = 0.3)
mz(sps_sub)

## This function can also be used to remove specific peaks from a spectrum
## by setting `keep = FALSE`.
sps_sub <- filterMzValues(data, mz = c(103, 104),
    tolerance = 0.3, keep = FALSE)
mz(sps_sub)

## Note that `filterMzValues` keeps or removes all peaks with a matching
## m/z given the provided `ppm` and `tolerance` parameters.

## Filter a Spectra keeping only peaks within a m/z range
sps_sub <- filterMzRange(data, mz = c(100, 300))
mz(sps_sub)

## Remove empty spectra variables
sciex_noNA <- dropNaSpectraVariables(sciex)

## Available spectra variables before and after dropNaSpectraVariables
spectraVariables(sciex)
spectraVariables(sciex_noNA)


## Adding new spectra variables
sciex1 <- filterDataOrigin(sciex, dataOrigin(sciex)[1])
spv <- DataFrame(spectrumId = sciex1$spectrumId[3:12], ## used for merging
                 var1 = rnorm(10),
                 var2 = sample(letters, 10))
spv

sciex2 <- joinSpectraData(sciex1, spv, by.y = "spectrumId")

spectraVariables(sciex2)
spectraData(sciex2)[1:13, c("spectrumId", "var1", "var2")]

## Removing fourier transform artefacts seen in Orbitra data.

## Loading an Orbitrap spectrum with artefacts.
data(fft_spectrum)
plotSpectra(fft_spectrum, xlim = c(264.5, 265.5))
plotSpectra(fft_spectrum, xlim = c(264.5, 265.5), ylim = c(0, 5e6))

fft_spectrum <- filterFourierTransformArtefacts(fft_spectrum)
fft_spectrum
plotSpectra(fft_spectrum, xlim = c(264.5, 265.5), ylim = c(0, 5e6))

## Using a few examples peaks in your data you can optimize the parameters
fft_spectrum_filtered <- filterFourierTransformArtefacts(fft_spectrum,
                                               halfWindowSize = 0.2,
                                               threshold = 0.005,
                                               keepIsotopes = TRUE,
                                               maxCharge = 5,
                                               isotopeTolerance = 0.005
                                               )

fft_spectrum_filtered
length(mz(fft_spectrum_filtered)[[1]])
plotSpectra(fft_spectrum_filtered, xlim = c(264.5, 265.5), ylim = c(0, 5e6))

## ---- DATA MANIPULATIONS AND OTHER OPERATIONS ----

## Set the data to be centroided
centroided(data) <- TRUE

## Replace peak intensities below 40 with 3.
res <- replaceIntensitiesBelow(data, threshold = 40, value = 3)
res

## Get the intensities of the first and second spectrum.
intensity(res)[[1]]
intensity(res)[[2]]

## Remove all peaks with an intensity below 40.
res <- filterIntensity(res, intensity = c(40, Inf))

## Get the intensities of the first and second spectrum.
intensity(res)[[1]]
intensity(res)[[2]]

## Lengths of spectra is now different
lengths(mz(res))
lengths(mz(data))

## In addition it is possible to pass a function to `filterIntensity`: in
## the example below we want to keep only peaks that have an intensity which
## is larger than one third of the maximal peak intensity in that spectrum.
keep_peaks <- function(x, prop = 3) {
    x > max(x, na.rm = TRUE) / prop
}
res2 <- filterIntensity(data, intensity = keep_peaks)
intensity(res2)[[1L]]
intensity(data)[[1L]]

## We can also change the proportion by simply passing the `prop` parameter
## to the function. To keep only peaks that have an intensity which is
## larger than half of the maximum intensity:
res2 <- filterIntensity(data, intensity = keep_peaks, prop = 2)
intensity(res2)[[1L]]
intensity(data)[[1L]]

## Since data manipulation operations are by default not directly applied to
## the data but only added to the internal lazy evaluation queue, it is also
## possible to remove these data manipulations with the `reset` function:
res_rest <- reset(res)
res_rest
lengths(mz(res_rest))
lengths(mz(res))
lengths(mz(data))

## `reset` after a `applyProcessing` can not restore the data, because the
## data in the backend was changed. Similarly, `reset` after any filter
## operations can not restore data for a `Spectra` with a
## `MsBackendMemory` or `MsBackendDataFrame`.
res_2 <- applyProcessing(res)
res_rest <- reset(res_2)
lengths(mz(res))
lengths(mz(res_rest))


## Compare spectra: comparing spectra 2 and 3 against spectra 10:20 using
## the normalized dotproduct method.
res <- compareSpectra(sciex_im[2:3], sciex_im[10:20])
## first row contains comparisons of spectrum 2 with spectra 10 to 20 and
## the second row comparisons of spectrum 3 with spectra 10 to 20
res

## To use a simple Pearson correlation instead we can define a function
## that takes the two peak matrices and calculates the correlation for
## their second columns (containing the intensity values).
correlateSpectra <- function(x, y, use = "pairwise.complete.obs", ...) {
    cor(x[, 2], y[, 2], use = use)
}
res <- compareSpectra(sciex_im[2:3], sciex_im[10:20],
    FUN = correlateSpectra)
res

## Use compareSpectra to determine the number of common (matching) peaks
## with a ppm of 10:
## type = "inner" uses a *inner join* to match peaks, i.e. keeps only
## peaks that can be mapped betwen both spectra. The provided FUN returns
## simply the number of matching peaks.
compareSpectra(sciex_im[2:3], sciex_im[10:20], ppm = 10, type = "inner",
    FUN = function(x, y, ...) nrow(x))

## Apply an arbitrary function to each spectrum in a Spectra.
## In the example below we calculate the mean intensity for each spectrum
## in a subset of the sciex_im data. Note that we can access all variables
## of each individual spectrum either with the `$` operator or the
## corresponding method.
res <- spectrapply(sciex_im[1:20], FUN = function(x) mean(x$intensity[[1]]))
head(res)

## It is however important to note that dedicated methods to access the
## data (such as `intensity`) are much more efficient than using `lapply`:
res <- lapply(intensity(sciex_im[1:20]), mean)
head(res)

## As an alternative, applying a function `FUN` to a `Spectra` can be
## performed *chunk-wise*. The advantage of this is, that only the data for
## one chunk at a time needs to be loaded into memory reducing the memory
## demand. This type of processing can be performed by specifying the size
## of the chunks (i.e. number of spectra per chunk) with the `chunkSize`
## parameter
spectrapply(sciex_im[1:20], lengths, chunkSize = 5L)

## Calculating the precursor intensity for MS2 spectra:
##
## Some MS instrument manufacturer don't report the precursor intensities
## for MS2 spectra. The `estimatePrecursorIntensity` function can be used
## in these cases to calculate the precursor intensity on MS1 data. Below
## we load an mzML file from a vendor providing precursor intensities and
## compare the estimated and reported precursor intensities.
tmt <- Spectra(msdata::proteomics(full.names = TRUE)[5],
    backend = MsBackendMzR())
pmi <- estimatePrecursorIntensity(tmt)
plot(pmi, precursorIntensity(tmt))

## We can also replace the original precursor intensity values with the
## newly calculated ones
tmt$precursorIntensity <- pmi

## ---- DATA EXPORT ----

## Some `MsBackend` classes provide an `export` method to export the data to
## the file format supported by the backend. The `MsBackendMzR` for example
## allows to export MS data to mzML or mzXML file(s), the `MsBackendMgf`
## (defined in the MsBackendMgf R package) would allow to export the data
## in mgf file format. Below we export the MS data in `data`. We
## call the `export` method on this object, specify the backend that should
## be used to export the data (and which also defines the output format) and
## provide a file name.
fl <- tempfile()
export(data, MsBackendMzR(), file = fl)

## This exported our data in mzML format. Below we read the first 6 lines
## from that file.
readLines(fl, n = 6)

## If only a single file name is provided, all spectra are exported to that
## file. To export data with the `MsBackendMzR` backend to different files, a
## file name for each individual spectrum has to be provided.
## Below we export each spectrum to its own file.
fls <- c(tempfile(), tempfile())
export(data, MsBackendMzR(), file = fls)

## Reading the data from the first file
res <- Spectra(backendInitialize(MsBackendMzR(), fls[1]))

mz(res)
mz(data)
}
\author{
Nir Shahaf, Johannes Rainer

Johannes Rainer

Sebastian Gibb, Johannes Rainer, Laurent Gatto
}
